from elevenlabs import set_api_key, clone, generate, save
from pydub import AudioSegment
import speech_recognition as sr
import moviepy.editor as mp
import pvleopard
from app.config import *
from typing import Sequence, Optional
import os
from moviepy.video.tools.subtitles import SubtitlesClip
import translators as ts
import openai

TMP_FILE = 'tmpsub.srt'

supported_languages = ['en',
                       'de',
                       'pl',
                       'es',
                       'it',
                       'fr',
                       'pt',
                       'hi']


def save_data(data, out_path, verbose=True):
    with open(out_path, 'wb') as f:
        f.write(data)
        if verbose:
            print('data saved to:', out_path)
    return out_path


def get_audio_from_video(video_path, out_path):
    # Warning: returns None if no audio track is present in the video
    audio = mp.VideoFileClip(video_path).audio
    audio.write_audiofile(out_path)
    return out_path


def convert_wav_to_mp3(wav_path, mp3_path):
    if wav_path.endswith('.wav'):
        AudioSegment.from_wav(wav_path).export(mp3_path, format="mp3")
    elif wav_path.endswith('.mp3'):
        AudioSegment.from_mp3(wav_path).export(mp3_path, format="mp3")
    else:
        raise Exception(f'File extension not supported: {wav_path}')
    return mp3_path


def get_text_from_audio(audio_path):
    leopard = pvleopard.create(access_key=LEO_API_KEY)
    transcript, words = leopard.process_file(audio_path)
    return transcript


def clone_voice(audio_path):
    voice_name = 'user_voice'
    cloned = clone(
        name=voice_name,
        description='User\'s cloned voice',
        files=[audio_path],
    )
    return cloned


def generate_audio(text, voice_to_use, out_path, model='eleven_multilingual_v1'):
    generated = generate(
        text=text,
        voice=voice_to_use,
        model="eleven_multilingual_v1",
    )
    save(generated, out_path)
    return out_path


def clone_and_generate_audio(text, audio_path, out_path):
    cloned_voice = clone_voice(audio_path)
    return generate_audio(text, cloned_voice, out_path)


def merge_audio_with_video(audio_path, video_path, out_path):
    video = mp.VideoFileClip(video_path)
    audio = mp.AudioFileClip(audio_path)
    ratio = video.duration/audio.duration
    print(ratio)
    video = video.fx(mp.vfx.speedx, ratio)
    final_video = video.set_audio(audio)
    with open(out_path, 'w') as f:
        final_video.write_videofile(out_path)
    return out_path


def second_to_timecode(x: float) -> str:
    hour, x = divmod(x, 3600)
    minute, x = divmod(x, 60)
    second, x = divmod(x, 1)
    millisecond = int(x * 1000.)

    return '%.2d:%.2d:%.2d,%.3d' % (hour, minute, second, millisecond)


def to_srt(
        words: Sequence[pvleopard.Leopard.Word],
        endpoint_sec: float = 1.,
        length_limit: Optional[int] = 16) -> str:
    def _helper(end: int) -> None:
        lines.append("%d" % section)
        lines.append(
            "%s --> %s" %
            (
                second_to_timecode(words[start].start_sec),
                second_to_timecode(words[end].end_sec)
            )
        )
        lines.append(' '.join(x.word for x in words[start:(end + 1)]))
        lines.append('')

    lines = list()
    section = 0
    start = 0
    for k in range(1, len(words)):
        if ((words[k].start_sec - words[k - 1].end_sec) >= endpoint_sec) or \
                (length_limit is not None and (k - start) >= length_limit):
            _helper(k - 1)
            start = k
            section += 1
    _helper(len(words) - 1)

    return '\n'.join(lines)


def generate_subtitles_from_audio(audio_input):
    leopard = pvleopard.create(
        access_key=LEO_API_KEY)
    _, words = leopard.process_file(audio_input)
    with open(TMP_FILE, 'w') as f:
        f.write(to_srt(words))
    return to_srt(words)


def combine_video_and_audio(video_input, audio_input):
    audio = mp.AudioFileClip(audio_input)
    video = mp.VideoFileClip(video_input)
    return video.set_audio(audio)


def combine_video_and_subtitles(video_input, subtitles) -> mp.VideoClip:
    def generator(txt): return mp.TextClip(
        txt, font='Verdana', fontsize=36, color='white', bg_color='black', align='center')#.set_pos('center', 'top')
    sub = SubtitlesClip(TMP_FILE, generator)
    sub.set_position(("center", "top"))  # TODO
    final = mp.CompositeVideoClip([video_input, sub])
    return final


def add_autogenerated_subtitles(video_path, audio_path) -> mp.VideoClip:
    video = combine_video_and_audio(video_path, audio_path)
    subs = generate_subtitles_from_audio(audio_path)
    video = combine_video_and_subtitles(video, subs)
    # os.remove(TMP_FILE)
    return video


def get_chunks(s, maxlength):
    start = 0
    end = 0
    while start + maxlength < len(s) and end != -1:
        end = s.rfind(" ", start, start + maxlength + 1)
        yield s[start:end]
        start = end + 1
    yield s[start:]


def translate_text(text, language):
    chunked_text = get_chunks(text, 1000)
    output = ""
    for t in chunked_text:
        print(t)
        output += ts.translate_text(t, to_language=language)
    return output


def translate_subtitles(input_file, output_file, language):
    with open(input_file) as f:
        lines = f.readlines()
    out_text = ts.translate_text(lines, to_language=language)
    with open(output_file, 'w') as f:
        f.write(out_text)


def synth_voice_from_text(text, voice):
    set_api_key(API_KEY_11)

    audio = generate(
        text=text,
        voice=voice,
        model="eleven_multilingual_v1"
    )
    return audio


def get_completion_from_messages(messages,
                                    model="gpt-3.5-turbo",
                                    temperature=0, max_tokens=500):
        response = openai.ChatCompletion.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
        )
        return response.choices[0].message["content"]


def add_puctuation(user_message):
    system_message = f"""
    Insert punctuation marks, without changing the text.
    """

    messages =  [
    {'role':'system',
    'content': system_message},
    {'role':'user',
    'content': user_message},
    ]

    response = get_completion_from_messages(messages)
    return response
